{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### データセットの場所やバッチサイズなどの定数値の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "\n",
    "\n",
    "# 使用するデバイス\n",
    "# GPU を使用しない環境（CPU環境）で実行する場合は DEVICE = 'cpu' とする\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "# 全ての訓練データを一回ずつ使用することを「1エポック」として，何エポック分学習するか\n",
    "# 再開モードの場合も, このエポック数の分だけ追加学習される（N_EPOCHSは最終エポック番号ではない）\n",
    "N_EPOCHS = 20\n",
    "\n",
    "# 学習時のバッチサイズ\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# 訓練データセット（画像ファイルリスト）のファイル名\n",
    "TRAIN_DATASET_CSV = './FakeFaces/train_list.csv'\n",
    "\n",
    "# テストデータセット（画像ファイルリスト）のファイル名\n",
    "TEST_DATASET_CSV = './FakeFaces/test_list.csv'\n",
    "\n",
    "# 画像ファイルの先頭に付加する文字列（データセットが存在するディレクトリのパス）\n",
    "DATA_DIR = './FakeFaces/'\n",
    "\n",
    "# 画像サイズ\n",
    "H = 256 # 縦幅\n",
    "W = 256 # 横幅\n",
    "C = 3 # 入力画像のチャンネル数（カラー画像なら3，グレースケール画像なら1．なお，正解のマスク画像のチャンネル数は常に1）\n",
    "\n",
    "# 学習結果の保存先フォルダ\n",
    "MODEL_DIR = './FakeFaces_models/'\n",
    "\n",
    "# 学習結果のニューラルネットワークの保存先\n",
    "MODEL_FILE = os.path.join(MODEL_DIR, 'fakeface_detector_model.pth')\n",
    "\n",
    "# 中断／再開の際に用いる一時ファイル\n",
    "CHECKPOINT_EPOCH = os.path.join(MODEL_DIR, 'checkpoint_epoch.pkl')\n",
    "CHECKPOINT_MODEL = os.path.join(MODEL_DIR, 'checkpoint_model.pth')\n",
    "CHECKPOINT_OPT = os.path.join(MODEL_DIR, 'checkpoint_opt.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ニューラルネットワークモデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 畳込み，バッチ正規化，ReLUをセットで行うクラス\n",
    "class myConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(myConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "# DeepFake Detection Challenge データセットの顔画像に対しReal/Fake判定を行うニューラルネットワーク\n",
    "class FakeFaceDetector(nn.Module):\n",
    "\n",
    "    # C: 入力画像のチャンネル数（1または3と仮定）\n",
    "    # H: 入力画像の縦幅（32の倍数と仮定）\n",
    "    # W: 入力画像の横幅（32の倍数と仮定）\n",
    "    def __init__(self, C, H, W):\n",
    "        super(FakeFaceDetector, self).__init__()\n",
    "\n",
    "        # 畳込み層1〜5\n",
    "        # カーネルサイズ3，ストライド幅1，パディング1の設定なので，これを通しても特徴マップの縦幅・横幅は変化しない\n",
    "        self.conv1 = myConv2d(in_channels=C, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = myConv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = myConv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = myConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = myConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # プーリング層1～5\n",
    "        # 1回適用するごとに特徴マップの縦幅・横幅がそれぞれ 1/2 になる\n",
    "        # 全部で5回適用することになるので，最終的には都合 1/32 になる -> ゆえに，入力画像の縦幅と横幅を各々32の倍数と仮定している\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # 平坦化\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        # 全結合層1\n",
    "        # 畳込み層1～5を通すことにより特徴マップの縦幅・横幅は都合 1/32 になっている．\n",
    "        # 従って，入力側のパーセプトロン数は 64*(H/32)*(W/32) = H*W/16\n",
    "        self.fc1 = nn.Linear(in_features=H*W//16, out_features=256)\n",
    "\n",
    "        # 全結合層2\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=2) # 最後はRealかFakeかの2クラス\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.pool1(self.conv1(x))\n",
    "        h = self.pool2(self.conv2(h))\n",
    "        h = self.pool3(self.conv3(h))\n",
    "        h = self.pool4(self.conv4(h))\n",
    "        h = self.pool5(self.conv5(h))\n",
    "        h = self.flat(h)\n",
    "        h = F.relu(self.fc1(h))\n",
    "        y = self.fc2(h)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 訓練データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from mylib.data_io import CSVBasedDataset\n",
    "from mylib.utility import save_datasets, load_datasets_from_file\n",
    "\n",
    "\n",
    "# 前回の試行の続きを行いたい場合は True にする -> 再開モードになる\n",
    "RESTART_MODE = False\n",
    "\n",
    "\n",
    "# 再開モードの場合は，前回使用したデータセットをロードして使用する\n",
    "if RESTART_MODE:\n",
    "    train_dataset, valid_dataset = load_datasets_from_file(MODEL_DIR)\n",
    "    if train_dataset is None:\n",
    "        print('error: there is no checkpoint previously saved.')\n",
    "        exit()\n",
    "    train_size = len(train_dataset)\n",
    "    valid_size = len(valid_dataset)\n",
    "    with open(os.path.join(MODEL_DIR, 'fdicts.pkl'), 'rb') as fdicts_file:\n",
    "        fdicts = pickle.load(fdicts_file)\n",
    "    n_classes = len(fdicts[1])\n",
    "\n",
    "# そうでない場合は，データセットを読み込む\n",
    "else:\n",
    "\n",
    "    # CSVファイルを読み込み, 訓練データセットを用意\n",
    "    dataset = CSVBasedDataset(\n",
    "        filename = TRAIN_DATASET_CSV,\n",
    "        items = [\n",
    "            'File Path', # X\n",
    "            'Label', # Y\n",
    "        ],\n",
    "        dtypes = [\n",
    "            'image', # Xの型\n",
    "            'label', # Yの型\n",
    "        ],\n",
    "        dirname = DATA_DIR,\n",
    "    )\n",
    "    with open(os.path.join(MODEL_DIR, 'fdicts.pkl'), 'wb') as fdicts_file:\n",
    "        pickle.dump(dataset.forward_dicts, fdicts_file)\n",
    "\n",
    "    # 訓練データセットを分割し，一方を検証用に回す\n",
    "    dataset_size = len(dataset)\n",
    "    valid_size = int(0.01 * dataset_size) # 全体の 1% を検証用に\n",
    "    train_size = dataset_size - valid_size # 残りの 99% を学習用に\n",
    "    train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "    # データセット情報をファイルに保存\n",
    "    save_datasets(MODEL_DIR, train_dataset, valid_dataset)\n",
    "\n",
    "# 訓練データおよび検証用データをミニバッチに分けて使用するための「データローダ」を用意\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 学習処理の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from mylib.visualizers import LossVisualizer\n",
    "from mylib.utility import save_checkpoint, load_checkpoint\n",
    "\n",
    "\n",
    "# 前回の試行の続きを行いたい場合は True にする -> 再開モードになる\n",
    "RESTART_MODE = False\n",
    "\n",
    "\n",
    "# エポック番号\n",
    "INIT_EPOCH = 0 # 初期値\n",
    "LAST_EPOCH = INIT_EPOCH + N_EPOCHS # 最終値\n",
    "\n",
    "# ニューラルネットワークの作成\n",
    "model = FakeFaceDetector(C=C, H=H, W=W).to(DEVICE)\n",
    "\n",
    "# 最適化アルゴリズムの指定（ここでは SGD でなく Adam を使用）\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 再開モードの場合は，前回チェックポイントから情報をロードして学習再開\n",
    "if RESTART_MODE:\n",
    "    INIT_EPOCH, LAST_EPOCH, model, optimizer = load_checkpoint(CHECKPOINT_EPOCH, CHECKPOINT_MODEL, CHECKPOINT_OPT, N_EPOCHS, model, optimizer)\n",
    "    print('')\n",
    "\n",
    "# 損失関数\n",
    "loss_func =  nn.CrossEntropyLoss()\n",
    "\n",
    "# 損失関数値を記録する準備\n",
    "loss_viz = LossVisualizer(['train loss', 'valid loss', 'accuracy'], init_epoch=INIT_EPOCH)\n",
    "\n",
    "# 勾配降下法による繰り返し学習\n",
    "for epoch in range(INIT_EPOCH, LAST_EPOCH):\n",
    "\n",
    "    print('Epoch {0}:'.format(epoch + 1))\n",
    "\n",
    "    # 学習\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    for X, Y in tqdm(train_dataloader):\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        X = X.to(DEVICE) # 入力画像\n",
    "        Y = Y.to(DEVICE) # RealかFakeかの2値ラベル\n",
    "        Y_pred = model(X) # 入力画像 X をニューラルネットワークに入力し，RealかFakeかの判定値 Y_pred を得る\n",
    "        loss = loss_func(Y_pred, Y) # 損失関数の現在値を計算\n",
    "        loss.backward() # 誤差逆伝播法により，個々のパラメータに関する損失関数の勾配（偏微分）を計算\n",
    "        optimizer.step() # 勾配に沿ってパラメータの値を更新\n",
    "        sum_loss += float(loss) * len(X)\n",
    "    avg_loss = sum_loss / train_size\n",
    "    loss_viz.add_value('train loss', avg_loss) # 訓練データに対する損失関数の値を記録\n",
    "    print('train loss = {0:.6f}'.format(avg_loss))\n",
    "\n",
    "    # 検証\n",
    "    model.eval()\n",
    "    sum_loss = 0\n",
    "    n_failed = 0\n",
    "    with torch.inference_mode():\n",
    "        for X, Y in tqdm(valid_dataloader):\n",
    "            X = X.to(DEVICE) # 入力画像\n",
    "            Y = Y.to(DEVICE) # RealかFakeかの2値ラベル\n",
    "            Y_pred = model(X)\n",
    "            loss = loss_func(Y_pred, Y)\n",
    "            sum_loss += float(loss) * len(X)\n",
    "            n_failed += float(torch.count_nonzero(torch.argmax(Y_pred, dim=1) - Y)) # 判定結果と正解が一致していないデータの個数を数える\n",
    "    avg_loss = sum_loss / valid_size\n",
    "    accuracy = (valid_size - n_failed) / valid_size\n",
    "    loss_viz.add_value('valid loss', avg_loss) # 検証用データに対する損失関数の値を記録\n",
    "    loss_viz.add_value('accuracy', accuracy) # 検証用データに対する判定精度の値を記録\n",
    "    print('valid loss = {0:.6f}'.format(avg_loss))\n",
    "    print('accuracy = {0:.2f}%'.format(100 * accuracy))\n",
    "    print('')\n",
    "\n",
    "    # 現在の学習状態を一時ファイルに保存\n",
    "    save_checkpoint(CHECKPOINT_EPOCH, CHECKPOINT_MODEL, CHECKPOINT_OPT, epoch+1, model, optimizer)\n",
    "\n",
    "# 学習結果のニューラルネットワークモデルをファイルに保存\n",
    "model = model.to('cpu')\n",
    "torch.save(model.state_dict(), MODEL_FILE)\n",
    "\n",
    "# 損失関数の記録をファイルに保存\n",
    "loss_viz.save(v_file=os.path.join(MODEL_DIR, 'loss_graph.png'), h_file=os.path.join(MODEL_DIR, 'loss_history.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 学習済みニューラルネットワークモデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# ニューラルネットワークモデルとその学習済みパラメータをファイルからロード\n",
    "model = FakeFaceDetector(C=C, H=H, W=W)\n",
    "model.load_state_dict(torch.load(MODEL_FILE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### テストデータセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from mylib.data_io import CSVBasedDataset\n",
    "\n",
    "\n",
    "# CSVファイルを読み込み, テストデータセットを用意\n",
    "with open(os.path.join(MODEL_DIR, 'fdicts.pkl'), 'rb') as fdicts_file:\n",
    "    fdicts = pickle.load(fdicts_file)\n",
    "test_dataset = CSVBasedDataset(\n",
    "    filename = TEST_DATASET_CSV,\n",
    "    items = [\n",
    "        'File Path', # X\n",
    "        'Label', # Y\n",
    "    ],\n",
    "    dtypes = [\n",
    "        'image', # Xの型\n",
    "        'label', # Yの型\n",
    "    ],\n",
    "    dirname = DATA_DIR,\n",
    "    fdicts = fdicts,\n",
    ")\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "# テストデータをミニバッチに分けて使用するための「データローダ」を用意\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### テスト処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# テストデータセットを用いて判定精度を評価\n",
    "n_failed = 0\n",
    "with torch.inference_mode():\n",
    "    for X, Y in tqdm(test_dataloader):\n",
    "        X = X.to(DEVICE)\n",
    "        Y = Y.to(DEVICE)\n",
    "        Y_pred = model(X)\n",
    "        n_failed += torch.count_nonzero(torch.argmax(Y_pred, dim=1) - Y) # 推定値と正解値が一致していないデータの個数を数える\n",
    "    accuracy = (test_size - n_failed) / test_size\n",
    "    print('accuracy = {0:.2f}%'.format(100 * accuracy))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
